---
title: week nine - Natural Language Processing.
bigimg: /img/wk-9.jpeg
comments: true
tags: [NLP, Text-analysis, nltk, ]
---
Natural Language Processing (NLP) is basically the combining of machine learning techniques with text and using math / statistics to get that text in a format that the machine learning algorithms can understand! 📖

NLP concerns itself with the interaction between natural human languages and computing devices. NLP is a major aspect of computational linguistics, and also falls within the realms of computer science and artificial intelligence.

As I got introduced to NLP, I came to the realization that the field is quite expanse and wide.

This will only highlight the basic concepts in this.

### What new skills have you learned?

📦   Natural Language Processing

#### Natural Language Processing
One easily referable application of NLP is email classification since it's relatable to many.

Using labeled these labeled ham(important mail) and spam examples, a machine learning model is trained to learn to discriminate between ham/spam automatically.

With this training, the model can then classify arbitrary unlabeled messages as ham or spam.

##### Components in NLP

🔅  Corpus  - A collection of texts.

💥  Feature engineering - Features to be used in training models. Domain knowledge on the data enhances your ability to engineer more features from it.

📌  Text Pre-processing -

📌  Normalization - Normalization generally refers to a series of related tasks meant to put all text on a level playing field: converting all text to the same case (upper or lower), removing punctuation, converting numbers to their word equivalents, and so on

Vectorization -

📌  TF-IDF - Term Frequency-Inverse Document Frequency, the tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus

📌  Stop words - are those words which are filtered out before further processing of text, since these words contribute little to overall meaning, given that they are generally the most common words in a language. For instance, "the," "and," and "a,"


📌  Stemming - the process of eliminating affixes (suffixed, prefixes, infixes, circumfixes) from a word in order to obtain a word stem.
            -   Singing  > Sing.
            -   Women's > Women

📌  Lammatization - is related to stemming, differing in that lemmatization is able to capture canonical forms based on a word's lemma.

            -   Greater >  Great
            -   Women   >  Woman

📌  Tokenization -  This is a step which splits longer strings of text into smaller pieces, or tokens. Larger chunks of text can be tokenized into sentences, sentences can be tokenized into words, etc.

📌  Bag of words  - is a particular representation model used to simplify the contents of a selection of text. The bag of words model omits grammar and word order, but is interested in the number of occurrences of words within the text


📌  C : A low C value equates to low Bias - high Variance

📌  gamma: small gamma results to gaussian with large Variance
    -   High gamma results to high Bias-low Variance.

Sample notebook with [iris dataset classification using SVM]


So that was the Eighth week.. 🔏

[iris dataset classification using SVM]:https://github.com/4bic/deliberate_practice/blob/master/jupyter%20notebooks/Support-Vector-Machines/svm_project.ipynb
